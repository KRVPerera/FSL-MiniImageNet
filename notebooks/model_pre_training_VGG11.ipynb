{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "#pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x29520d15850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "from src.data_loader import imshow\n",
    "from src.modelvis import visualize_models\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "'''\n",
    "The line cudnn.benchmark = True is typically used in deep learning projects that utilize the CUDA Deep Neural Network (cuDNN) library.\n",
    "When cudnn.benchmark is set to True, it enables cuDNN to automatically find the best algorithm configuration for the specific \n",
    "input sizes and hardware being used. This can result in improved performance during training and inference.By enabling benchmarking, \n",
    "cuDNN will run a short benchmarking phase during the first iteration of the model to determine the optimal algorithm configuration. \n",
    "This configuration is then cached and used for subsequent iterations, leading to faster execution times.\n",
    "It's important to note that enabling benchmarking may introduce some overhead during the initial benchmarking phase, so it is typically \n",
    "recommended to use it when the input sizes are consistent throughout the training process.\n",
    "Overall, setting cudnn.benchmark to True can help optimize the performance of deep learning models that use cuDNN.\n",
    "'''\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "'''\n",
    "The line plt.ion() is a function call that activates interactive mode in matplotlib.\n",
    "When interactive mode is enabled, any plot that is created will be displayed immediately \n",
    "and can be updated dynamically. This means that you can modify the plot after it is displayed, \n",
    "such as changing the data or adding annotations, and the changes will be reflected in real-time.\n",
    "'''\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16.1+cpu\n",
      "2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# timm.list_models(pretrained=True)\n",
    "from torchvision.models import vgg11, VGG11_Weights\n",
    "\n",
    "class VGG11_FC_Changed(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        weights = VGG11_Weights.DEFAULT\n",
    "        self.model = vgg11(weights=weights, progress=False)\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        self.transform = weights.transforms(antialias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.transform(x)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(84),\n",
    "        # transforms.RandomResizedCrop(84),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.GaussianBlur(3,sigma=(0.5, 2.0)),\n",
    "        transforms.RandomRotation(degrees=(0, 30)),\n",
    "        transforms.RandomAdjustSharpness(0.25),\n",
    "        transforms.RandomAutocontrast(0.25),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'tune': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomAdjustSharpness(0.25),\n",
    "        transforms.RandomAutocontrast(0.25),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "def GetDataLoaders(data_dir, batch_size=4, shuffle=True, num_workers=4, validation_split=0.2, test_split=0.1):\n",
    "    original_train_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])\n",
    "\n",
    "    num_samples = len(original_train_dataset)\n",
    "    num_val = int(validation_split * num_samples)\n",
    "    num_test = int(test_split * num_samples)\n",
    "    num_train = num_samples - num_val - num_test\n",
    "\n",
    "    # Split the dataset into train, validation, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(original_train_dataset, [num_train, num_val, num_test])\n",
    "\n",
    "    # Create data loaders for each set\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader,\n",
    "        'test': test_loader\n",
    "    }\n",
    "    dataset_sizes = {\n",
    "        'train': num_train,\n",
    "        'val': num_val,\n",
    "        'test': num_test\n",
    "    }\n",
    "    class_names = original_train_dataset.classes\n",
    "\n",
    "    return dataloaders, class_names, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_func(net, data_loader):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "    else:\n",
    "        print(\"No Cude\")\n",
    "    net.eval()\n",
    "    correct = 0.0\n",
    "    num_images = 0.0\n",
    "    for i_batch, (images, labels) in enumerate(data_loader):\n",
    "        if use_cuda:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outs = net(images) \n",
    "#         _, preds = outs.max(1)\n",
    "        preds = outs.argmax(dim=1)\n",
    "        correct += preds.eq(labels).sum()\n",
    "        num_images += len(labels)\n",
    "\n",
    "    acc = correct / num_images\n",
    "    return acc\n",
    "\n",
    "# references: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, dataset_sizes):\n",
    "    since = time.time()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    else:\n",
    "        print(\"No Cude\")\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        train_losses = [] # Log the training loss\n",
    "        train_avg_losses = [] # Log the training loss\n",
    "        val_losses = []\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                correct = 0.0 # used to accumulate number of correctly recognized images\n",
    "                num_images = 0.0 # used to accumulate number of images\n",
    "                epoch_loss = 0.0\n",
    "                \n",
    "                # Iterate over data.\n",
    "                for i_batch, (images, labels) in enumerate(dataloaders[phase]):\n",
    "                    if use_cuda:\n",
    "                        images = images.cuda()\n",
    "                        labels = labels.cuda()\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(images)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            epoch_loss += loss.item()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item()\n",
    "                    running_corrects += torch.sum(preds == labels)\n",
    "                if phase == 'train':\n",
    "                    # scheduler.step()\n",
    "                    train_losses.append(loss.item())\n",
    "                    train_avg_losses.append(epoch_loss / dataset_sizes[phase])\n",
    "                else:\n",
    "                    val_losses.append(loss.item())\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "        \n",
    "        plt.title('Train and Validation losses')\n",
    "        plt.plot(train_losses, label='training losses')\n",
    "        plt.plot(val_losses, label='validation losses')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T_0 = 1000 # Number of iterations for the first restart.\n",
    "LEARNING_RATE=0.001 # 0.0001\n",
    "WEIGHT_DECAY=0.0005 # 0.000001\n",
    "NUM_EPOCHS=15\n",
    "BATCH_SIZE=64\n",
    "MOMENTUM=0.9\n",
    "num_of_classes = 64\n",
    "STEP_SIZE=7\n",
    "GAMMA=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SHUFFLE=True\n",
    "WORKERS=4\n",
    "num_images = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = '..\\\\data\\\\miniImageNet\\\\train'\n",
    "dataloaders, class_names, dataset_sizes  = GetDataLoaders(data_dir, BATCH_SIZE, SHUFFLE, num_workers=WORKERS)\n",
    "\n",
    "train_loader = dataloaders['train']\n",
    "validation_loader = dataloaders['val']\n",
    "test_loader = dataloaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to C:\\Users\\ruksh/.cache\\torch\\hub\\checkpoints\\vgg11-8a719046.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait patiently, it may take some seconds...\n",
      "No Cude\n",
      "Epoch 0/14\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39mSTEP_SIZE, gamma\u001b[38;5;241m=\u001b[39mGAMMA)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease wait patiently, it may take some seconds...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m best_model \u001b[38;5;241m=\u001b[39m train_model(net, dataloaders, criterion, optimizer, scheduler, NUM_EPOCHS, dataset_sizes)\n\u001b[0;32m      9\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbest_model_vgg11.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(best_model\u001b[38;5;241m.\u001b[39mstate_dict(), save_path)\n",
      "File \u001b[1;32mE:\\Masters\\Period2\\DeepLearning\\Assignments\\few-shot-MiniImageNet-EuroSAT\\notebooks\\..\\src\\training.py:85\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, optimizer, scheduler, num_epochs, dataset_sizes)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# backward + optimize only if in training phase\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 85\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     86\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     87\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = VGG11_FC_Changed(num_of_classes).to(device)\n",
    "for p in net.parameters():\n",
    "    p.requires_grad = True\n",
    "net.train()\n",
    "optimizer = torch.optim.SGD(params= net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "print('Please wait patiently, it may take some seconds...')\n",
    "best_model = train_model(net, dataloaders, criterion, optimizer, scheduler, NUM_EPOCHS, dataset_sizes)\n",
    "save_path = '..\\\\data\\\\models\\\\best_model_vgg11.pth'\n",
    "torch.save(best_model.state_dict(), save_path)\n",
    "\n",
    "eval_acc = eval_func(best_model, dataloaders['test'])\n",
    "print('')\n",
    "print('Accuracy on testing data: %f' % eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.load_state_dict(torch.load(save_path))\n",
    "visualize_models(best_model, dataloaders, num_images, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
