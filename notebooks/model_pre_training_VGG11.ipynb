{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1e3ebcad040>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "from src.training import train_model, eval_func\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "from src.data_loader import imshow\n",
    "from src.modelvis import visualize_models\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "'''\n",
    "The line cudnn.benchmark = True is typically used in deep learning projects that utilize the CUDA Deep Neural Network (cuDNN) library.\n",
    "When cudnn.benchmark is set to True, it enables cuDNN to automatically find the best algorithm configuration for the specific \n",
    "input sizes and hardware being used. This can result in improved performance during training and inference.By enabling benchmarking, \n",
    "cuDNN will run a short benchmarking phase during the first iteration of the model to determine the optimal algorithm configuration. \n",
    "This configuration is then cached and used for subsequent iterations, leading to faster execution times.\n",
    "It's important to note that enabling benchmarking may introduce some overhead during the initial benchmarking phase, so it is typically \n",
    "recommended to use it when the input sizes are consistent throughout the training process.\n",
    "Overall, setting cudnn.benchmark to True can help optimize the performance of deep learning models that use cuDNN.\n",
    "'''\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "'''\n",
    "The line plt.ion() is a function call that activates interactive mode in matplotlib.\n",
    "When interactive mode is enabled, any plot that is created will be displayed immediately \n",
    "and can be updated dynamically. This means that you can modify the plot after it is displayed, \n",
    "such as changing the data or adding annotations, and the changes will be reflected in real-time.\n",
    "'''\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16.1+cu118\n",
      "2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timm.list_models(pretrained=True)\n",
    "from torchvision.models import vgg11, VGG11_Weights\n",
    "\n",
    "class VGG11_FC_Changed(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        weights = VGG11_Weights.DEFAULT\n",
    "        self.model = vgg11(weights=weights, progress=False)\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        self.transform = weights.transforms(antialias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.transform(x)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(84),\n",
    "        # transforms.RandomResizedCrop(84),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.GaussianBlur(3,sigma=(0.5, 2.0)),\n",
    "        transforms.RandomRotation(degrees=(0, 30)),\n",
    "        transforms.RandomAdjustSharpness(0.25),\n",
    "        transforms.RandomAutocontrast(0.25),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'tune': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomAdjustSharpness(0.25),\n",
    "        transforms.RandomAutocontrast(0.25),\n",
    "        transforms.RandomEqualize(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "def GetDataLoaders(data_dir, batch_size=4, shuffle=True, num_workers=4, validation_split=0.2, test_split=0.1):\n",
    "    original_train_dataset = datasets.ImageFolder(data_dir, data_transforms['train'])\n",
    "\n",
    "    num_samples = len(original_train_dataset)\n",
    "    num_val = int(validation_split * num_samples)\n",
    "    num_test = int(test_split * num_samples)\n",
    "    num_train = num_samples - num_val - num_test\n",
    "\n",
    "    # Split the dataset into train, validation, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(original_train_dataset, [num_train, num_val, num_test])\n",
    "\n",
    "    # Create data loaders for each set\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader,\n",
    "        'test': test_loader\n",
    "    }\n",
    "    dataset_sizes = {\n",
    "        'train': num_train,\n",
    "        'val': num_val,\n",
    "        'test': num_test\n",
    "    }\n",
    "    class_names = original_train_dataset.classes\n",
    "\n",
    "    return dataloaders, class_names, dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_0 = 1000 # Number of iterations for the first restart.\n",
    "LEARNING_RATE=0.001 # 0.0001\n",
    "WEIGHT_DECAY=0.0005 # 0.000001\n",
    "NUM_EPOCHS=15\n",
    "BATCH_SIZE=64\n",
    "MOMENTUM=0.9\n",
    "num_of_classes = 64\n",
    "STEP_SIZE=7\n",
    "GAMMA=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE=True\n",
    "WORKERS=16\n",
    "num_images = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = '..\\\\data\\\\miniImageNet\\\\train'\n",
    "dataloaders, class_names, dataset_sizes  = GetDataLoaders(data_dir, BATCH_SIZE, SHUFFLE, num_workers=WORKERS)\n",
    "\n",
    "train_loader = dataloaders['train']\n",
    "validation_loader = dataloaders['val']\n",
    "test_loader = dataloaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to C:\\Users\\rperera23/.cache\\torch\\hub\\checkpoints\\vgg11-8a719046.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait patiently, it may take some seconds...\n",
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.0595 Acc: 0.0834\n",
      "val Loss: 0.0446 Acc: 0.2796\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.0418 Acc: 0.2996\n"
     ]
    }
   ],
   "source": [
    "net = VGG11_FC_Changed(num_of_classes).to(device)\n",
    "for p in net.parameters():\n",
    "    p.requires_grad = True\n",
    "net.train()\n",
    "optimizer = torch.optim.SGD(params= net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "print('Please wait patiently, it may take some seconds...')\n",
    "best_model = train_model(net, dataloaders, criterion, optimizer, scheduler, NUM_EPOCHS, dataset_sizes)\n",
    "save_path = '..\\\\data\\\\models\\\\best_model_vgg11.pth'\n",
    "torch.save(best_model.state_dict(), save_path)\n",
    "\n",
    "eval_acc = eval_func(best_model, dataloaders['test'])\n",
    "print('')\n",
    "print('Accuracy on testing data: %f' % eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.load_state_dict(torch.load(save_path))\n",
    "visualize_models(best_model, dataloaders, num_images, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
