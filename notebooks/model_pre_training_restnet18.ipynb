{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 uninstall torch torchvision torchaudio\n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ResNet18_Weights' from 'torchvision.models' (C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\torchvision\\models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18708\\2163577846.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mResnet18_FC_Changed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Oulun yliopisto\\DeepLearning\\few-shot-MiniImageNet-EuroSAT\\notebooks\\..\\src\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResNet18_Weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvgg11_bn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVGG11_BN_Weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgooglenet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGoogLeNet_Weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ResNet18_Weights' from 'torchvision.models' (C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\torchvision\\models\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "from src.training import train_model, eval_func\n",
    "from src.models import Resnet18_FC_Changed\n",
    "import os\n",
    "from torchvision import datasets, models, transforms\n",
    "from src.data_loader import imshow, GetDataLoaders\n",
    "from src.modelvis import visualize_models\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "'''\n",
    "The line cudnn.benchmark = True is typically used in deep learning projects that utilize the CUDA Deep Neural Network (cuDNN) library.\n",
    "When cudnn.benchmark is set to True, it enables cuDNN to automatically find the best algorithm configuration for the specific \n",
    "input sizes and hardware being used. This can result in improved performance during training and inference.By enabling benchmarking, \n",
    "cuDNN will run a short benchmarking phase during the first iteration of the model to determine the optimal algorithm configuration. \n",
    "This configuration is then cached and used for subsequent iterations, leading to faster execution times.\n",
    "It's important to note that enabling benchmarking may introduce some overhead during the initial benchmarking phase, so it is typically \n",
    "recommended to use it when the input sizes are consistent throughout the training process.\n",
    "Overall, setting cudnn.benchmark to True can help optimize the performance of deep learning models that use cuDNN.\n",
    "'''\n",
    "cudnn.benchmark = True\n",
    "\n",
    "'''\n",
    "The line plt.ion() is a function call that activates interactive mode in matplotlib.\n",
    "When interactive mode is enabled, any plot that is created will be displayed immediately \n",
    "and can be updated dynamically. This means that you can modify the plot after it is displayed, \n",
    "such as changing the data or adding annotations, and the changes will be reflected in real-time.\n",
    "'''\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_0 = 1000 # Number of iterations for the first restart.\n",
    "LEARNING_RATE=0.001 # 0.0001\n",
    "WEIGHT_DECAY=0.0005 # 0.000001\n",
    "NUM_EPOCHS=15\n",
    "BATCH_SIZE=64\n",
    "MOMENTUM=0.9\n",
    "num_of_classes = 64\n",
    "STEP_SIZE=7\n",
    "GAMMA=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE=True\n",
    "WORKERS=16\n",
    "num_images = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_dir = '..\\\\data\\\\miniImageNet'\n",
    "dataloaders, class_names, dataset_sizes  = GetDataLoaders(data_dir, BATCH_SIZE, SHUFFLE, num_workers=WORKERS)\n",
    "\n",
    "train_loader = dataloaders['train']\n",
    "validation_loader = dataloaders['val']\n",
    "test_loader = dataloaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import Resnet18_FC_Changed\n",
    "net = Resnet18_FC_Changed(num_of_classes).to(device)\n",
    "for p in net.parameters():\n",
    "    p.requires_grad = True\n",
    "net.train()\n",
    "optimizer = torch.optim.SGD(params= net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "print('Please wait patiently, it may take some seconds...')\n",
    "best_model = train_model(net, dataloaders, criterion, optimizer, scheduler, NUM_EPOCHS, dataset_sizes)\n",
    "save_path = '..\\\\data\\\\models\\\\best_model_Resnet18.pth'\n",
    "torch.save(best_model.state_dict(), save_path)\n",
    "\n",
    "eval_acc = eval_func(best_model, dataloaders['test'])\n",
    "print('')\n",
    "print('Accuracy on testing data: %f' % eval_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.load_state_dict(torch.load(save_path))\n",
    "visualize_models(best_model, dataloaders, num_images, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
