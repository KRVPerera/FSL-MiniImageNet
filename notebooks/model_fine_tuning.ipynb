{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gdown in c:\\users\\rperera23\\appdata\\roaming\\python\\python39\\site-packages (4.7.1)\n",
      "Requirement already satisfied: six in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests[socks]->gdown) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests[socks]->gdown) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\program files\\arcgis\\pro\\bin\\python\\envs\\arcgispro-py3\\lib\\site-packages (from tqdm->gdown) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1d56534e070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "from src.models import ModelResnet152dTimm\n",
    "from src.dataloader import EuroSatDownloader\n",
    "from src.training import train_fine_tuning, eval_method, eval_func\n",
    "from src.dataloader import MiniImageNetDataSet, createEuroSatDataLoaders, EuroSatDownloader\n",
    "from src.modelvis import visualize_models\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "'''\n",
    "The line cudnn.benchmark = True is typically used in deep learning projects that utilize the CUDA Deep Neural Network (cuDNN) library.\n",
    "When cudnn.benchmark is set to True, it enables cuDNN to automatically find the best algorithm configuration for the specific \n",
    "input sizes and hardware being used. This can result in improved performance during training and inference.By enabling benchmarking, \n",
    "cuDNN will run a short benchmarking phase during the first iteration of the model to determine the optimal algorithm configuration. \n",
    "This configuration is then cached and used for subsequent iterations, leading to faster execution times.\n",
    "It's important to note that enabling benchmarking may introduce some overhead during the initial benchmarking phase, so it is typically \n",
    "recommended to use it when the input sizes are consistent throughout the training process.\n",
    "Overall, setting cudnn.benchmark to True can help optimize the performance of deep learning models that use cuDNN.\n",
    "'''\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "'''\n",
    "The line plt.ion() is a function call that activates interactive mode in matplotlib.\n",
    "When interactive mode is enabled, any plot that is created will be displayed immediately \n",
    "and can be updated dynamically. This means that you can modify the plot after it is displayed, \n",
    "such as changing the data or adding annotations, and the changes will be reflected in real-time.\n",
    "'''\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.2\n",
      "1.8.2\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download EuroSat Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:05:02,863 - INFO - EuroSat database already exists.\n"
     ]
    }
   ],
   "source": [
    "extractDir = '..\\\\data'\n",
    "url = \"https://zenodo.org/records/7711810/files/EuroSAT_RGB.zip?download=1\"\n",
    "downloader = EuroSatDownloader(url, extractDir)\n",
    "dataDir = downloader.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "WEIGHT_DECAY = 0.00001\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 2\n",
    "MOMENTUM = 0.09\n",
    "STEP_SIZE = 1\n",
    "num_of_classes = 64\n",
    "EPISODES = 5\n",
    "GAMMA = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.3, 0.3, 0.2), (0.5, 0.6, 0.5)),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "       transforms.Normalize((0.3, 0.3, 0.2), (0.5, 0.6, 0.5)),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.3, 0.3, 0.2), (0.5, 0.6, 0.5)),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "dataDir = '..\\\\data\\\\miniImageNet\\\\train'\n",
    "modelPath = '..\\\\data\\\\models\\\\best_model_ModelResnet152dTimm_FixedTransforms.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait patiently, it may take some seconds...\n",
      "\n",
      "Training Episode: 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:05:07,003 - INFO - Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet152d_ra2-5cac0439.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 0.320000, avg. loss: 1.533763, test accuracy: 0.133333\n",
      "epoch: 1, accuracy: 0.400000, avg. loss: 1.475761, test accuracy: 0.266667\n",
      "epoch: 2, accuracy: 0.440000, avg. loss: 1.486629, test accuracy: 0.226667\n",
      "Episode 1: Test Accuracy: 0.2267 num of images: 75\n",
      "\n",
      "Training Episode: 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:05:25,206 - INFO - Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet152d_ra2-5cac0439.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 0.240000, avg. loss: 1.606491, test accuracy: 0.280000\n",
      "epoch: 1, accuracy: 0.280000, avg. loss: 1.547183, test accuracy: 0.293333\n",
      "epoch: 2, accuracy: 0.320000, avg. loss: 1.536868, test accuracy: 0.293333\n",
      "Episode 2: Test Accuracy: 0.2933 num of images: 75\n",
      "\n",
      "Training Episode: 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:05:40,508 - INFO - Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet152d_ra2-5cac0439.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 0.240000, avg. loss: 1.630154, test accuracy: 0.226667\n",
      "epoch: 1, accuracy: 0.160000, avg. loss: 1.622713, test accuracy: 0.266667\n",
      "epoch: 2, accuracy: 0.280000, avg. loss: 1.595363, test accuracy: 0.266667\n",
      "Episode 3: Test Accuracy: 0.2667 num of images: 75\n",
      "\n",
      "Training Episode: 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:05:53,390 - INFO - Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet152d_ra2-5cac0439.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 0.240000, avg. loss: 1.619021, test accuracy: 0.226667\n",
      "epoch: 1, accuracy: 0.160000, avg. loss: 1.590062, test accuracy: 0.306667\n",
      "epoch: 2, accuracy: 0.240000, avg. loss: 1.588618, test accuracy: 0.280000\n",
      "Episode 4: Test Accuracy: 0.2800 num of images: 75\n",
      "\n",
      "Training Episode: 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 01:06:08,193 - INFO - Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet152d_ra2-5cac0439.pth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 0.240000, avg. loss: 1.601058, test accuracy: 0.213333\n",
      "epoch: 1, accuracy: 0.160000, avg. loss: 1.583845, test accuracy: 0.213333\n",
      "epoch: 2, accuracy: 0.400000, avg. loss: 1.565922, test accuracy: 0.240000\n",
      "Episode 5: Test Accuracy: 0.2400 num of images: 75\n",
      "\n",
      "Average Test Accuracy: 0.2613333333333333\n"
     ]
    }
   ],
   "source": [
    "print('Please wait patiently, it may take some seconds...')\n",
    "total_test_acc = 0.0\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    print(f\"\\nTraining Episode: {episode + 1}...\")\n",
    "    \n",
    "    loaded_model = torch.load(modelPath, map_location=device)\n",
    "    model = ModelResnet152dTimm(64)\n",
    "    model.load_state_dict(loaded_model)\n",
    "    model.model.fc = nn.Linear(model.model.fc.in_features, 5).to(device)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(params = model.parameters(), lr = LEARNING_RATE, momentum = MOMENTUM, weight_decay = WEIGHT_DECAY)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = STEP_SIZE, gamma = GAMMA)\n",
    "    dataloaders, class_names, dataset_sizes = createEuroSatDataLoaders(data_transforms, dataDir, split=0.25, batch_size = BATCH_SIZE)\n",
    "    \n",
    "    model, _, _ = train_fine_tuning(model, dataloaders, criterion, optimizer, scheduler, num_epochs = NUM_EPOCHS, learning_rate = LEARNING_RATE)\n",
    "    test_loader = dataloaders['test']\n",
    "    acc_test, test_loss = eval_method(net=model, data_loader=test_loader)\n",
    "    total_test_acc += acc_test\n",
    "    print(f\"Episode {episode + 1}: Test Accuracy: {acc_test:.4f}\")\n",
    "\n",
    "average_test_acc = total_test_acc / EPISODES\n",
    "print(\"\\nAverage Test Accuracy:\", average_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
